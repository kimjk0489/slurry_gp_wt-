import streamlit as st
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_mll
from gpytorch.mlls import ExactMarginalLogLikelihood
from botorch.acquisition.analytic import ExpectedImprovement
from botorch.optim import optimize_acqf

st.set_page_config(page_title="Slurry ì¡°ì„± ìµœì í™” GP", layout="wide")
st.title("Slurry ì¡°ì„± ìµœì í™” GP")

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
CSV_PATH = "slurry_data_wt%_ALL.csv"
df = pd.read_csv(CSV_PATH)

# 2. ì‚¬ìš©ì ì…ë ¥: ì‚¬ì´ë“œë°”ë¡œ ìƒˆë¡œìš´ ì¡°ì„± ì¶”ê°€
st.sidebar.header("ğŸ“¥ ìƒˆë¡œìš´ ì‹¤í—˜ ì¡°ì„± ì¶”ê°€")
with st.sidebar.form("new_data_form"):
    new_cb = st.number_input("Carbon Black [wt%]", step=0.1)
    new_graphite = st.number_input("Graphite [wt%]", step=0.1)
    new_cmc = st.number_input("CMC [wt%]", step=0.05)
    new_solvent = st.number_input("Solvent [wt%]", step=0.5)
    new_yield = st.number_input("Yield Stress [Pa]", step=10.0)
    submitted = st.form_submit_button("ë°ì´í„° ì¶”ê°€")

if submitted:
    new_row = {
        "carbon_black_wt%": new_cb,
        "graphite_wt%": new_graphite,
        "CMC_wt%": new_cmc,
        "solvent_wt%": new_solvent,
        "yield_stress": new_yield,
    }
    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
    df.to_csv(CSV_PATH, index=False)
    st.sidebar.success("âœ… ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# 3. ì…ë ¥/ì¶œë ¥ ì„¤ì •
x_cols = ["carbon_black_wt%", "graphite_wt%", "CMC_wt%", "solvent_wt%"]
y_cols = ["yield_stress"]
X_raw = df[x_cols].values
Y_raw = df[y_cols].values

# 4. ì •ê·œí™” ë²”ìœ„ ì •ì˜
param_bounds = {
    "carbon_black_wt%": (1.75, 10.0),
    "graphite_wt%":     (18.0, 38.0),
    "CMC_wt%":          (0.7, 1.5),
    "solvent_wt%":      (58.0, 78.0),
}
bounds_array = np.array([param_bounds[k] for k in x_cols])
x_scaler = MinMaxScaler()
x_scaler.fit(bounds_array.T)

X_scaled = x_scaler.transform(X_raw)
train_x = torch.tensor(X_scaled, dtype=torch.double)
train_y = torch.tensor(Y_raw, dtype=torch.double)

# 5. GP ëª¨ë¸ í•™ìŠµ
model = SingleTaskGP(train_x, train_y)
mll = ExactMarginalLogLikelihood(model.likelihood, model)
fit_gpytorch_mll(mll)

# 6. ì œì•½ì¡°ê±´ ì„¤ì •
input_dim = train_x.shape[1]
bounds = torch.tensor([[0.0] * input_dim, [1.0] * input_dim], dtype=torch.double)

scales = bounds_array[:, 1] - bounds_array[:, 0]
offset = np.sum(bounds_array[:, 0])
rhs = 100.0 - offset
indices = torch.arange(len(x_cols), dtype=torch.long)
coefficients = torch.tensor(scales, dtype=torch.double)
rhs_tensor = torch.tensor(rhs, dtype=torch.double)

inequality_constraints = [
    (indices, coefficients, rhs_tensor),
    (indices, -coefficients, -rhs_tensor),
]

candidate_wt = None

# ì¤‘ë³µ í™•ì¸ í•¨ìˆ˜
def is_duplicate(candidate_scaled, train_scaled, tol=1e-3):
    return any(np.allclose(candidate_scaled, x, atol=tol) for x in train_scaled)

# 7. ì¶”ì²œ ë²„íŠ¼ ëˆ„ë¥´ë©´ ìˆ˜í–‰
if st.button("Candidate"):
    best_y = train_y.max().item()
    acq_fn = ExpectedImprovement(model=model, best_f=best_y, maximize=True)

    for _ in range(10):
        candidate_scaled, _ = optimize_acqf(
            acq_function=acq_fn,
            bounds=bounds,
            q=1,
            num_restarts=10,
            raw_samples=100,
            inequality_constraints=inequality_constraints,
        )
        candidate_np = candidate_scaled.detach().numpy()[0]
        if is_duplicate(candidate_np, train_x.numpy()):
            continue
        x_tensor = torch.tensor(candidate_np.reshape(1, -1), dtype=torch.double)
        y_pred = model.posterior(x_tensor).mean.item()

        if y_pred > 0:
            candidate_wt = x_scaler.inverse_transform(candidate_np.reshape(1, -1))[0]
            break

    if candidate_wt is not None:
        st.subheader("Candidate")
        for i, col in enumerate(x_cols):
            st.write(f"{col}: **{candidate_wt[i]:.2f} wt%**")
        st.write(f"**ì´í•©**: {np.sum(candidate_wt):.2f} wt%")
        st.write(f"**ì˜ˆì¸¡ Yield Stress**: {y_pred:.2f} Pa")
    else:
        st.warning("Yield Stress > 0 ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¡°ì„±ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# 8. Carbon Black ë³€í™”ì— ë”°ë¥¸ ì˜ˆì¸¡ ì‹œê°í™”
cb_idx = x_cols.index("carbon_black_wt%")
x_vals_scaled = np.linspace(0, 1, 100)
mean_scaled = np.mean(X_scaled, axis=0)
X_test_scaled = np.tile(mean_scaled, (100, 1))
X_test_scaled[:, cb_idx] = x_vals_scaled
X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.double)

model.eval()
with torch.no_grad():
    posterior = model.posterior(X_test_tensor)
    mean = posterior.mean.numpy().flatten()
    std = posterior.variance.sqrt().numpy().flatten()

cb_vals_wt = x_scaler.inverse_transform(X_test_scaled)[:, cb_idx]
train_x_cb = x_scaler.inverse_transform(train_x.numpy())[:, cb_idx]
train_y_np = train_y.numpy().flatten()

fig, ax = plt.subplots(figsize=(10, 5))
ax.plot(cb_vals_wt, mean, label="Predicted Mean", color="blue")
ax.fill_between(cb_vals_wt, mean - 1.96 * std, mean + 1.96 * std, color="blue", alpha=0.2, label="95% CI")
ax.scatter(train_x_cb, train_y_np, color="red", label="Observed Data")
if candidate_wt is not None:
    cand_scaled = x_scaler.transform(candidate_wt.reshape(1, -1))
    pred_y = model.posterior(torch.tensor(cand_scaled, dtype=torch.double)).mean.item()
    ax.scatter(candidate_wt[cb_idx], pred_y, color="yellow", label="Candidate")

ax.set_xlabel("Carbon Black [wt%]")
ax.set_ylabel("Yield Stress [Pa]")
ax.set_title("GP Prediction")
ax.grid(True)
ax.legend()
st.pyplot(fig)
